{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project: Effect of Cryptocurrency pricing and demand on the global chip market.\n",
    "\n",
    "# Permissions\n",
    "\n",
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that student names will be included (but PIDs will be scraped from any groups who include their PIDs).\n",
    "\n",
    "* [X] YES - make available\n",
    "* [ ] NO - keep private\n",
    "\n",
    "# Names\n",
    "\n",
    "- Benjamin Xia\n",
    "- Kailey Wong\n",
    "- Jesus Tello\n",
    "- Jungwoon Ko\n",
    "- Yusuke Yanagawa\n",
    "\n",
    "# Abstract\n",
    "\n",
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much of an impact do cryptocurrency miners/prices actually have on GPU prices and stock for individual customers (e.g. gamers)? Are there any other factors that have had a larger impact (e.g. global chip shortages affecting GPUs and other kinds of chips)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Graphics Processing Units (a.k.a. GPUs, graphics cards, video cards) allow computers to perform parallel computations on a scale that is simply impossible on most traditional processing units (central processing units, a.k.a. CPUs). GPUs have allowed faster data processing, rendering, training for machine learning algorithms, and more. Gaming on a low-spec potato laptop often hinders the smooth play of demanding triple-A titles due to hardware limitations. To cope, users must reduce graphics settings, sacrificing visual quality for better performance. However, some games may still remain unplayable, necessitating the exploration of less demanding titles or an upgrade to a more powerful system. Many game developers are even expecting players to have powerful machines as an excuse not to optimize their games to perform well on lower-end machines properly.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) As computer graphics continue to progress and games become more graphically intensive, demand for consumer-grade GPUs such as NVIDIA's Geforce lineup has only grown.\n",
    "\n",
    "When cryptocurrency became mainstream (around 2017), more people started mining cryptocurrencies with consumer-grade GPUs due to their unreasonable effectiveness compared to traditional processors and the lack of supply for ASIC (Application-Specific Integrated Circuit) units specialized for cryptocurrency mining.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) Cryptocurrency miners, along with the onset of the pandemic led to GPU supplies dwindling, leading gamers to start blaming cryptocurrency miners for GPU shortages and sky-high pricing by eBay scalpers. Many GPU models, such as the NVIDIA GTX 1000 series and RTX 3000 series, were unavailable at MSRP (Manufacturer's Suggested Retail Price) for months. Gamers' reaction to the GPU market is evident by overall sentiment on online communities such as Reddit.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) Vendors have attempted to allow more individual customers to get their hands on these precious GPUs by imposing purchase limits.<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4)\n",
    "\n",
    "The story of how GPU prices skyrocketed has since become a case study in how supply and demand can swiftly decimate a consumer market.<a name=\"cite_ref-5\"></a>[<sup>5</sup>](#cite_note-5)\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Crider, Michael (7 Sep 2023) Pre-Crypto Prices When? *PCWorld*. https://www.pcworld.com/article/2058969/trouble-running-starfield-todd-howard-says-upgrade-your-pc.html\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Iyer, S.G., Pawar, A. Dipakumar. (28 Feb 2019) GPU and CPU Accelerated Mining of Cryptocurrencies and their Financial Analysis *IEEE*. https://ieeexplore.ieee.org/document/8653733\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) u/rcmaehl (18 Nov 2018) Pre-Crypto Prices When? *r/pcmasterrace*. https://www.reddit.com/r/pcmasterrace/comments/9ygmux/precrypto_prices_when/\n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Dent, Steve (11 Feb 2022) Best Buy Limits Sales of NVIDIA RTX-Series GPUs to Totaltech Subscribers. *EnGadget*. https://www.engadget.com/best-buy-gpu-sales-totaltech-membership-paywall-092357559.html\n",
    "5. <a name=\"cite_note-5\"></a> [^](#cite_ref-5) Lim, H.W., Wibowo, T. (12 Apr 2022) Cryptocurrency Mining Effects On Semiconductor Shortage on PC Owner Community. *CoMBInES - Conference On Management, Business, Innovation, Education And Social Sciences*. https://journal.uib.ac.id/index.php/combines/article/view/6634"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suspect that cryptocurrency miners do have some impact on GPU prices and supply (in that there is some positive correlation between cryptocurrency prices and GPU prices), though its impact is often exaggerated by gamers on online communities as external factors such as chip (semiconductor) shortages often have a greater impact on price and supply. We believe this to be the case because many vendors often place limits on how many GPUs customers can purchase at at a time, and many of the GPU shortages have happened to coincide with global chip shortages (that were not isolated to GPUs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name: Steam Hardware Surveys\n",
    "  - Link to the dataset: https://raw.githubusercontent.com/jdegene/steamHWsurvey/master/shs.csv\n",
    "  - Number of observations: 9543\n",
    "  - Number of variables: 5\n",
    "  \n",
    "Each observation in this data set has a date for the date of the survey response, category for the type of hardware the entry is for, the name of the particular product, the percentage change in popularity from the previous month (negative values indicate less popularity, positive more popularity), and the percentage of total items in the category that the particular product makes up. The date, category, and name are strings, and the change and percentage are floats. This data will help us to understand the usage of particular GPU products over time. To wrangle and clean the dataset, we will need to filter the data by dates and the hardware category we are interested in, then check for and drop rows with missing data.\n",
    "\n",
    "- Dataset #2\n",
    "  - Dataset Name: Bitcoin USD Historical Data\n",
    "  - Link to the dataset: https://finance.yahoo.com/quote/BTC-USD/history?period1=1420070400&period2=1698796800&interval=1mo&filter=history&frequency=1mo&includeAdjustedClose=true\n",
    "  - Number of observations: 107\n",
    "  - Number of variables: 7 \n",
    "  \n",
    "Each observation in this data set has a date to indicate what month/year the data corresponds to, the opening price, the highest price during that month, the lowest price during that month, the closing price for that month, an adjusted closing price for splits/dividend/capital gain distributions (all in USD/floats), and volume of stocks traded during that month (integers). This data will help us to understand how bitcoin prices fluctuate overtime. We are able to preselect the dates we are interested in when downloading the csv for the data, so to wrangle and clean the dataset, we only need to check for missing data, and standardize the column headers to make it easier to combine datasets later on.\n",
    "\n",
    "- Dataset #3\n",
    "    - Dataset Name: Ethereum USD Historical Data\n",
    "  - Link to the dataset: https://finance.yahoo.com/quote/ETH-USD/history?period1=1510185600&period2=1698796800&interval=1mo&filter=history&frequency=1mo&includeAdjustedClose=true\n",
    "  - Number of observations: 72\n",
    "  - Number of variables: 7\n",
    "  \n",
    "Same as for bitcoin, each observation in this data set has a date to indicate what month/year the data corresponds to, the opening price, the highest price during that month, the lowest price during that month, the closing price for that month, an adjusted closing price for splits/dividend/capital gain distributions (all in USD/floats), and volume of stocks traded during that month (integers). This data will serve as another proxy to help us to understand how bitcoin prices fluctuate overtime. We are able to preselect the dates we are interested in when downloading the csv for the data, so to wrangle and clean the dataset, we only need to check for missing data, and standardize the column headers to make it easier to combine datasets later on (being able to distinguish between BTC vs ETH data).\n",
    "\n",
    "- Dataset #4\n",
    "  - Dataset Name: Historical CPU sell price/sell volume\n",
    "  - Link to the dataset: Scraped from [Ebay Terapeak](https://www.ebay.com/help/selling/selling-tools/terapeak-research?id=4853)\n",
    "  - Number of observations: 18527\n",
    "  - Number of variables: 4\n",
    "\n",
    "This was scraped from Ebay Terapeak using the script in our repository `ebay_scraper.py`. Each observation has a UNIX timestamp (which could easily be converted to month/year), model name, along with that CPU model's average sell price each week (in USD) and average count of units sold that week. This data will serve as a proxy to help us understand how GPU and CPU prices and supply have changed over time, and we will take a look at how they relate to each other (CPU vs. GPU prices), and cryptocurrency prices over time. The data we collected is (mostly) clean, though we do need to remove observations that come before a model was released, as an Intel 13700k would obviously have 0 units sold in 2020 as it wasn't even released then. The datatypes are integer timestamps, model names as strings, sell price in USD (integers, though Pandas will interpret them as floats by default), and units sold as integers. \n",
    "\n",
    "- Dataset #5\n",
    "  - Dataset Name: Historical GPU sell price/sell volume\n",
    "  - Link to the dataset: Scraped from [Ebay Terapeak](https://www.ebay.com/help/selling/selling-tools/terapeak-research?id=4853)\n",
    "  - Number of observations: 6438\n",
    "  - Number of variables: 4\n",
    "\n",
    "Identical format to dataset #4.\n",
    "This was scraped from Ebay Terapeak using the script in our repository `ebay_scraper.py`. Each observation has a UNIX timestamp (which could easily be converted to month/year), model name, along with that GPU model's average sell price each week (in USD) and average count of units sold that week. This data will serve as a proxy to help us understand how GPU and CPU prices and supply have changed over time, and we will take a look at how they relate to each other (CPU vs. GPU prices), and cryptocurrency prices over time. The data we collected is (mostly) clean, though we do need to remove observations that come before a model was released, as an RTX 4080 would obviously have 0 units sold in 2020 as it wasn't even released then. The datatypes are integer timestamps, model names as strings, sell price in USD (integers, though Pandas will interpret them as floats by default), and units sold as integers. \n",
    "\n",
    "- Dataset #6\n",
    "  - Dataset Name: CPU Launch MSRP's\n",
    "  - Link to the dataset: Scraped from [Benchmark.ul.com](https://benchmarks.ul.com/compare/best-cpus)\n",
    "  - Number of observations: 130\n",
    "  - Number of variables: 2\n",
    "\n",
    "This was scraped from Benchmark.ul.com using the notebook in our repository `./EDAjupyterNote/cpu_msrp.ipynb`. Each observation contains a model name (string) and its MSRP (Manufacturer Suggested Retail Price) (initially strings). This data will be used alongside our historical price-data to help us gauge how much CPU prices have been inflated (or not) at different points in time. The data we collected is mostly clean/tidy, though there are a few observations with missing prices that we will need to throw out. We also need to do a tiny bit of preprocessing to turn the MSRP from strings into integers. We still need to standardize the model names to fit the format defined in CPU historical prices/sell volume data.\n",
    "\n",
    "- Dataset #7\n",
    "  - Dataset Name: GPU Launch MSRP's\n",
    "  - Link to the dataset: Scraped from [cgdirector.com](https://www.cgdirector.com/gpu-msrp-list/)\n",
    "  - Number of observations: 57\n",
    "  - Number of variables: 2\n",
    "  \n",
    "This was scraped from cgdirector.com using the notebook in our repository `./EDAjupyterNote/gpu_msrp_scraper.ipynb`. Each observation contains a model name (string) and its MSRP (Manufacturer Suggested Retail Price) (initially strings). This data will be used alongside our historical price-data to help us gauge how much GPU prices have been inflated (or not) at different points in time. The data we collected is mostly clean/tidy, though some preprocessing was already done in `gpu_msrp_scraper.ipynb`. We still need to standardize the model names to fit the format defined in Steam's hardware survey data.\n",
    "\n",
    "To combine these datasets, we will take their intersection based on the dates. We may need to combine observations from our CPU and GPU data to be monthly in order to accomplish this (though this may not be completely necessary).The datasets also use different names to refer to the same CPU/GPU models (e.g. NVIDIA GeForce GTX 1080 vs. Nvidia GTX 1080), so we will also need to do a bit of wrangling to get the naming scheme to be consistent. Some datasets also contain data for hardware that may not be present in other datasets (e.g. niche parts in Steam's Hardware Survey that we didn't scrape for), we will likely only be focusing on the components that appear in all relevant datasets we are working with for a particular analysis, as there are enough components that the missing data should have little to no impact on our analysis. In other words, if we have data for price for product A but not MSRP when analyzing price vs. MSRP, we will not include product A in that analysis. Once the data is all \"synced\" up, we can combine different kinds of data into a signle table for finer-grained analysis of different variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Steam Hardware Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "steam_survey = pd.read_csv('https://raw.githubusercontent.com/jdegene/steamHWsurvey/master/shs.csv')\n",
    "\n",
    "# Check out the data\n",
    "steam_survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the survey responses by date\n",
    "# We will only be looking at data from the last 8 years, or since 2015\n",
    "# Reset the indexes\n",
    "steam_dates = steam_survey[pd.to_datetime(steam_survey['date']).dt.year >= 2015].reset_index().drop(labels='index',axis=1)\n",
    "steam_dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What types of categories are in this dataset?\n",
    "steam_dates['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2 (if you have more than one, use name instead of number here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "Carry out whatever EDA you need to for your project.  Because every project will be different we can't really give you much of a template at this point. But please make sure you describe the what and why in text here as well as providing interpretation of results and context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Analysis You Did - Give it a better title\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Analysis You Did - Give it a better title\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETC AD NASEUM\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discusison and Conclusion\n",
    "\n",
    "Wrap it all up here.  Somewhere between 3 and 10 paragraphs roughly.  A good time to refer back to your Background section and review how this work extended the previous stuff. \n",
    "\n",
    "\n",
    "# Team Contributions\n",
    "\n",
    "Speficy who did what.  This should be pretty granular, perhaps bullet points, no more than a few sentences per person."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
